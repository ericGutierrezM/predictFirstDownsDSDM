Metadata-Version: 2.4
Name: firstDown
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.13
Description-Content-Type: text/markdown
Requires-Dist: aiofiles>=25.1.0
Requires-Dist: catboost>=1.2.8
Requires-Dist: category-encoders>=2.9.0
Requires-Dist: fastapi>=0.124.4
Requires-Dist: flask>=3.1.2
Requires-Dist: ipykernel>=7.1.0
Requires-Dist: lightgbm>=4.6.0
Requires-Dist: nflreadpy>=0.1.5
Requires-Dist: numpy>=2.3.5
Requires-Dist: pandas>=2.3.3
Requires-Dist: pyarrow>=22.0.0
Requires-Dist: pytest>=9.0.2
Requires-Dist: scikit-learn>=1.8.0
Requires-Dist: xgboost>=3.1.2

# ðŸˆ _firstDown_: Predicting First Downs in the NFL
#### Computing for Data Science | Barcelona School of Economics | December 2025
> Daniel Campos & Eric GutiÃ©rrez
---
## Motivation
_firstDown_ is a Python library envisioned to get the most out of the vast amount of sports-related data available! Although it has been designed to predict first downs (play success) in the NFL, its structure allows for changes and additions that make possible to perform data analysis on (virtually) any sports. So no matter if it's an extra yard, mile, goal, or point, _firstDown_ will get you there!

## About the dataset: ```nflreadpy```
In the ready-to-implement case provided by _firstDown_, we leverage the large amount of NFL play-by-play and player data from ```nflreadpy```. If you have in mind a sports dataset that you want to test out with _firstDown_, visit the documentation for more information on how to integrate it!

## A note on required libraries
The _pyproject.toml_ file in this repository contains all the dependencies needed for the library to run. Please, make sure to install them all in your system before trying out that model that keeps you up at night!

## On _firstDown_'s structure and scaling
The structure of this library aims at making its scaling straightforward: enabling the integration of new functionalities and methods. _firstDown_ is organized in sublibraries as following:

> 1. feature_engineering 
- Build new features, and get the most out of them by using encoders.

> 2. graph
- Generate customizable graphs to visualize your analysis.

> 3. hyper_tuning
- Perform a randomized search to get the best hyperparameters for your models.

> 4. load_data
- Load your favorite datasets to perform data analysis and modelling.

> 5. metrics
- Assess the performance of your models.

> 6. preprocessing
- Clean your data and prepare it for analysis.

> 7. train
- Train your models. 

## Ready-to-implement use case. Predicting First Downs in the NFL
In the file _test.ipynb_ inside the _notebooks_ folder an example pipeline to use _firstDown_ is provided.
